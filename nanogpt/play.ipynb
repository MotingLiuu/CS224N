{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import *\n",
    "import torch\n",
    "from torch import nn as nn\n",
    "import tiktoken\n",
    "device = ('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = tiktoken.get_encoding('gpt2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You\n"
     ]
    }
   ],
   "source": [
    "with open('input.txt', 'r') as f:\n",
    "    text = f.read()\n",
    "data = text[:1000]\n",
    "print(data[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoaaderLite:\n",
    "    \n",
    "    def __init__(self, B, T):\n",
    "        self.B = B\n",
    "        self.T = T\n",
    "        \n",
    "        with open('input.txt', 'r') as f:\n",
    "            text = f.read()\n",
    "        enc = tiktoken.get_encoding('gpt2')\n",
    "        tokens = enc.encode(text)\n",
    "        self.tokens = torch.tensor(tokens)\n",
    "        print(f'loaded {len(self.tokens)} tokens')\n",
    "        print(f'1 epoch = {len(self.tokens) // (B * T)} batches')\n",
    "        \n",
    "        self.current_position = 0\n",
    "        \n",
    "    def next_batch(self):\n",
    "        B, T = self.B, self.T\n",
    "        buf = self.tokens[self.current_position : self.current_position+B*T+1]\n",
    "        x = (buf[:-1]).view(B, T)\n",
    "        y = (buf[1:]).view(B, T)\n",
    "        self.current_position += B*T\n",
    "        if self.current_position + (B*T + 1) > len(self.tokens):\n",
    "            self.current_position = 0\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_test = text[:1000]\n",
    "tokens = enc.encode(text_test)\n",
    "B, T = 4, 32\n",
    "buf =torch.tensor(tokens[:B*T + 1]).to(device)\n",
    "x = buf[:-1].view(B, T)\n",
    "y = buf[1:].view(B, T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 123.65M\n"
     ]
    }
   ],
   "source": [
    "mconf = GPTConfig(vocab_size=50304)\n",
    "model = GPT(mconf).t   o(device)\n",
    "model = torch.compile(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 338025 tokens\n",
      "1 epoch = 82 batches\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoaaderLite(B=4, T=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.bfloat16\n",
      "step 0, loss: 10.902325630187988\n",
      "torch.bfloat16\n",
      "step 1, loss: 9.481597900390625\n",
      "torch.bfloat16\n",
      "step 2, loss: 8.97270393371582\n",
      "torch.bfloat16\n",
      "step 3, loss: 8.71376895904541\n",
      "torch.bfloat16\n",
      "step 4, loss: 8.384568214416504\n",
      "torch.bfloat16\n",
      "step 5, loss: 8.01504898071289\n",
      "torch.bfloat16\n",
      "step 6, loss: 7.911421775817871\n",
      "torch.bfloat16\n",
      "step 7, loss: 7.689092636108398\n",
      "torch.bfloat16\n",
      "step 8, loss: 7.636319160461426\n",
      "torch.bfloat16\n",
      "step 9, loss: 7.368589401245117\n",
      "torch.bfloat16\n",
      "step 10, loss: 7.3798112869262695\n",
      "torch.bfloat16\n",
      "step 11, loss: 7.400235176086426\n",
      "torch.bfloat16\n",
      "step 12, loss: 7.430852890014648\n",
      "torch.bfloat16\n",
      "step 13, loss: 7.351262092590332\n",
      "torch.bfloat16\n",
      "step 14, loss: 6.9875593185424805\n",
      "torch.bfloat16\n",
      "step 15, loss: 6.977277755737305\n",
      "torch.bfloat16\n",
      "step 16, loss: 6.749427795410156\n",
      "torch.bfloat16\n",
      "step 17, loss: 6.588696002960205\n",
      "torch.bfloat16\n",
      "step 18, loss: 6.7233076095581055\n",
      "torch.bfloat16\n",
      "step 19, loss: 6.719150543212891\n",
      "torch.bfloat16\n",
      "step 20, loss: 6.897652626037598\n",
      "torch.bfloat16\n",
      "step 21, loss: 6.743782043457031\n",
      "torch.bfloat16\n",
      "step 22, loss: 6.684950828552246\n",
      "torch.bfloat16\n",
      "step 23, loss: 6.7637715339660645\n",
      "torch.bfloat16\n",
      "step 24, loss: 6.794864654541016\n",
      "torch.bfloat16\n",
      "step 25, loss: 6.776001453399658\n",
      "torch.bfloat16\n",
      "step 26, loss: 6.624480247497559\n",
      "torch.bfloat16\n",
      "step 27, loss: 6.666062355041504\n",
      "torch.bfloat16\n",
      "step 28, loss: 6.700011730194092\n",
      "torch.bfloat16\n",
      "step 29, loss: 6.525743007659912\n",
      "torch.bfloat16\n",
      "step 30, loss: 6.463495254516602\n",
      "torch.bfloat16\n",
      "step 31, loss: 6.396812915802002\n",
      "torch.bfloat16\n",
      "step 32, loss: 6.434419631958008\n",
      "torch.bfloat16\n",
      "step 33, loss: 6.5694780349731445\n",
      "torch.bfloat16\n",
      "step 34, loss: 6.563188076019287\n",
      "torch.bfloat16\n",
      "step 35, loss: 6.572048187255859\n",
      "torch.bfloat16\n",
      "step 36, loss: 6.375455856323242\n",
      "torch.bfloat16\n",
      "step 37, loss: 6.526995658874512\n",
      "torch.bfloat16\n",
      "step 38, loss: 6.358397483825684\n",
      "torch.bfloat16\n",
      "step 39, loss: 6.170153617858887\n",
      "torch.bfloat16\n",
      "step 40, loss: 6.276524543762207\n",
      "torch.bfloat16\n",
      "step 41, loss: 6.393774509429932\n",
      "torch.bfloat16\n",
      "step 42, loss: 6.215373516082764\n",
      "torch.bfloat16\n",
      "step 43, loss: 6.202424049377441\n",
      "torch.bfloat16\n",
      "step 44, loss: 6.369813919067383\n",
      "torch.bfloat16\n",
      "step 45, loss: 6.262726783752441\n",
      "torch.bfloat16\n",
      "step 46, loss: 6.121974468231201\n",
      "torch.bfloat16\n",
      "step 47, loss: 6.137678146362305\n",
      "torch.bfloat16\n",
      "step 48, loss: 6.15293025970459\n",
      "torch.bfloat16\n",
      "step 49, loss: 6.069389820098877\n",
      "torch.bfloat16\n",
      "step 50, loss: 6.19170618057251\n",
      "torch.bfloat16\n",
      "step 51, loss: 6.113668441772461\n",
      "torch.bfloat16\n",
      "step 52, loss: 6.504631519317627\n",
      "torch.bfloat16\n",
      "step 53, loss: 6.43401575088501\n",
      "torch.bfloat16\n",
      "step 54, loss: 6.250011444091797\n",
      "torch.bfloat16\n",
      "step 55, loss: 6.352774620056152\n",
      "torch.bfloat16\n",
      "step 56, loss: 6.614473342895508\n",
      "torch.bfloat16\n",
      "step 57, loss: 6.516290664672852\n",
      "torch.bfloat16\n",
      "step 58, loss: 6.237841606140137\n",
      "torch.bfloat16\n",
      "step 59, loss: 6.367578506469727\n",
      "torch.bfloat16\n",
      "step 60, loss: 6.257873058319092\n",
      "torch.bfloat16\n",
      "step 61, loss: 6.231042861938477\n",
      "torch.bfloat16\n",
      "step 62, loss: 6.337155342102051\n",
      "torch.bfloat16\n",
      "step 63, loss: 6.200790882110596\n",
      "torch.bfloat16\n",
      "step 64, loss: 6.045278549194336\n",
      "torch.bfloat16\n",
      "step 65, loss: 6.222385406494141\n",
      "torch.bfloat16\n",
      "step 66, loss: 6.452581882476807\n",
      "torch.bfloat16\n",
      "step 67, loss: 6.29853630065918\n",
      "torch.bfloat16\n",
      "step 68, loss: 6.275216102600098\n",
      "torch.bfloat16\n",
      "step 69, loss: 6.120347023010254\n",
      "torch.bfloat16\n",
      "step 70, loss: 5.979837417602539\n",
      "torch.bfloat16\n",
      "step 71, loss: 6.293743133544922\n",
      "torch.bfloat16\n",
      "step 72, loss: 6.308127403259277\n",
      "torch.bfloat16\n",
      "step 73, loss: 6.075024604797363\n",
      "torch.bfloat16\n",
      "step 74, loss: 6.137201309204102\n",
      "torch.bfloat16\n",
      "step 75, loss: 6.28216028213501\n",
      "torch.bfloat16\n",
      "step 76, loss: 6.0260233879089355\n",
      "torch.bfloat16\n",
      "step 77, loss: 5.816310882568359\n",
      "torch.bfloat16\n",
      "step 78, loss: 5.858213901519775\n",
      "torch.bfloat16\n",
      "step 79, loss: 5.875698089599609\n",
      "torch.bfloat16\n",
      "step 80, loss: 6.4310150146484375\n",
      "torch.bfloat16\n",
      "step 81, loss: 6.281159400939941\n",
      "torch.bfloat16\n",
      "step 82, loss: 6.205075263977051\n",
      "torch.bfloat16\n",
      "step 83, loss: 6.171761512756348\n",
      "torch.bfloat16\n",
      "step 84, loss: 6.180091857910156\n",
      "torch.bfloat16\n",
      "step 85, loss: 6.1756134033203125\n",
      "torch.bfloat16\n",
      "step 86, loss: 5.888853073120117\n",
      "torch.bfloat16\n",
      "step 87, loss: 5.780608654022217\n",
      "torch.bfloat16\n",
      "step 88, loss: 5.755675315856934\n",
      "torch.bfloat16\n",
      "step 89, loss: 5.7065205574035645\n",
      "torch.bfloat16\n",
      "step 90, loss: 5.799305438995361\n",
      "torch.bfloat16\n",
      "step 91, loss: 5.693517684936523\n",
      "torch.bfloat16\n",
      "step 92, loss: 5.929166316986084\n",
      "torch.bfloat16\n",
      "step 93, loss: 6.011542320251465\n",
      "torch.bfloat16\n",
      "step 94, loss: 6.1483154296875\n",
      "torch.bfloat16\n",
      "step 95, loss: 6.131345272064209\n",
      "torch.bfloat16\n",
      "step 96, loss: 5.932561874389648\n",
      "torch.bfloat16\n",
      "step 97, loss: 5.9546613693237305\n",
      "torch.bfloat16\n",
      "step 98, loss: 5.780181884765625\n",
      "torch.bfloat16\n",
      "step 99, loss: 5.747770309448242\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    x, y = train_loader.next_batch()\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    with torch.autocast(device_type=device, dtype=torch.bfloat16):\n",
    "        logits, loss = model(x, y)\n",
    "    print(logits.dtype)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f'step {i}, loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.autocast(device_type=device, dtype=torch.bfloat16):\n",
    "    logits, loss = model(x, y)\n",
    "loss.dtype"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CS224N",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
